{"componentChunkName":"component---src-templates-blog-post-js","path":"/MGC/","result":{"data":{"site":{"siteMetadata":{"title":"Hi, I am Venky!"}},"markdownRemark":{"id":"e2b58c31-ed2e-5fd3-8219-bf435c2772c8","excerpt":"In one of my projects titled “Deep Learning multi-model to classify music genre”, I created a hybrid system using a novel approach to classify music genre by…","html":"<p>In one of my projects titled “Deep Learning multi-model to classify music genre”, I created a hybrid system using a novel approach to classify music genre by combining audio model and text model to improve performance. The <strong>goal of the project was to improve targeted user recommendation</strong> in music streaming domains. I used the dataset provided by US Library of Congress to train the model. For the audio model I used <strong>dense NN</strong> and for the text model I used LSTM, <strong>CNN</strong> along with TF-IDF and concatenated them using <strong>Keras functional API in Python</strong>.</p>\n<p>I faced many challenges during the implementation. With the <strong>huge dataset and the feature size of around 500 dimension</strong>, the data processing and cleaning was initial big challenge., so I used XGBoost to do feature selection and engineering, to find the optimal set of features giving best model performance. Unbalanced data with 12 output classes has great effect on the model, to handle that <strong>I used oversampling techniques like SMOTE</strong>.  During the model training, I had to iteratively fine-tune the hyperparameters like number of neurons, number of neural layers, batch size etc on the limited hardware processing power. I implemented techniques like early stopping, <strong>L2 Regularization to avoid model overfitting</strong>. For the text data extracted from web-scraping using an API, it had lot of bad samples and needed extensive data cleaning. Training individual models and then the hybrid model iteratively for best parameters and performance took long times of execution, to handle that I used <strong>threading for parallel batch processing</strong> which improved the training time.</p>\n<p>After completing the project successfully achieving best validation accuracy, I learned that using multi modal approach and more useful features of the data improves the accuracy and performance of model. I learned to handle huge dataset with vast number of feature dimension.</p>\n<p>I learned to implement multiple techniques to process the data and different methods to handle data imbalance, model fine-tuning using  regulariaztion and hyperparamteres.</p>\n<p>I learned to handle the complexity of the architecture from designing, data preparation to training and testing. I learned to handle hardware limitations using threading and concurrency.</p>\n<p>As a result, I grew more experienced and confident in terms of handling highly complex tasks with ambiguous inputs, implemented at a large scale. This project helped me learn to overcome roadblocks and try creative approaches to solve hard problems .</p>","frontmatter":{"title":"Music Genre Classification","date":"May 28, 2015","description":"This is a custom description for SEO and Open Graph purposes, rather than the default generated excerpt. Simply add a description field to the frontmatter."}},"previous":{"fields":{"slug":"/my-second-post/"},"frontmatter":{"title":"My Second Post!"}},"next":null},"pageContext":{"id":"e2b58c31-ed2e-5fd3-8219-bf435c2772c8","previousPostId":"b578d11b-6812-5f73-b523-4bc566a347b5","nextPostId":null}},"staticQueryHashes":["2841359383","3257411868"],"slicesMap":{}}